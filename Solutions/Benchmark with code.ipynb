{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an analysis for the DrivenData competition on predicting Heart Disease: https://www.drivendata.org/competitions/54/machine-learning-with-a-heart/page/107/\n",
    "\n",
    "The goal is to predict the binary class ```heart_disease_present```, which represents whether or not a patient has heart disease:\n",
    "\n",
    "- ```0``` represents no heart disease present\n",
    "- ```1``` represents heart disease present\n",
    "\n",
    "There are 14 columns in the dataset, where the ```patient_id``` column is a unique and random identifier. The remaining 13 features are described in the section below.\n",
    "- ```slope_of_peak_exercise_st_segment``` (type: int): the slope of the peak exercise ST segment, an electrocardiography read out indicating quality of blood flow to the heart\n",
    "- ```thal``` (type: categorical): results of thallium stress test measuring blood flow to the heart, with possible values ```normal```, ```fixed_defect```, ```reversible_defect```\n",
    "- ```resting_blood_pressure``` (type: int): resting blood pressure\n",
    "- ```chest_pain_type``` (type: int): chest pain type (4 values)\n",
    "- ```num_major_vessels``` (type: int): number of major vessels (0-3) colored by flourosopy\n",
    "- ```fasting_blood_sugar_gt_120_mg_per_dl``` (type: binary): fasting blood sugar > 120 mg/dl\n",
    "- ```resting_ekg_results``` (type: int): resting electrocardiographic results (values 0,1,2)\n",
    "- ```serum_cholesterol_mg_per_dl``` (type: int): serum cholestoral in mg/dl\n",
    "- ```oldpeak_eq_st_depression``` (type: float): oldpeak = ST depression induced by exercise relative to - rest, a measure of abnormality in electrocardiograms\n",
    "- ```sex``` (type: binary): ```0```: female, ```1```: male\n",
    "- ```age``` (type: int): age in years\n",
    "- ```max_heart_rate_achieved``` (type: int): maximum heart rate achieved (beats per minute)\n",
    "- ```exercise_induced_angina``` (type: binary): exercise-induced chest pain (```0```: False, ```1```: True)\n",
    "\n",
    "Performance is evaluated according to binary log loss.\n",
    "\n",
    "The format for the submission file is two columns with the ```patient_id``` and ```heart_disease_present```. This competition uses log loss as its evaluation metric, so the ```heart_disease_present``` values you should submit are the probabilities that a patient has heart disease (not the binary label)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load required packages\n",
    "\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as sklm\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import define and create the data folder\n",
    "data_folder = os.path.join(os.getcwd(), 'Data')\n",
    "os.makedirs(data_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#download the data\n",
    "urllib.request.urlretrieve('https://s3.amazonaws.com/drivendata/data/54/public/train_values.csv', filename=os.path.join(data_folder, 'train-features.csv'))\n",
    "urllib.request.urlretrieve('https://s3.amazonaws.com/drivendata/data/54/public/train_labels.csv', filename=os.path.join(data_folder, 'train-labels.csv'))\n",
    "urllib.request.urlretrieve('https://s3.amazonaws.com/drivendata/data/54/public/test_values.csv', filename=os.path.join(data_folder, 'test-features.csv'))\n",
    "urllib.request.urlretrieve('https://s3.amazonaws.com/drivendata/data/54/public/submission_format.csv', filename=os.path.join(data_folder, 'submission-format.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import the data into the notebook and defined first column as index (patient id)\n",
    "train_features = pd.read_csv(os.path.join(data_folder, 'train-features.csv'),index_col=0)\n",
    "train_labels = pd.read_csv(os.path.join(data_folder, 'train-labels.csv'), index_col=0)\n",
    "test_features = pd.read_csv(os.path.join(data_folder, 'test-features.csv'), index_col=0)\n",
    "submission_format = pd.read_csv(os.path.join(data_folder, 'submission-format.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create one training dataframe\n",
    "\n",
    "train_features['heart_disease_present'] = train_labels['heart_disease_present']\n",
    "\n",
    "heart = train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#check how the first rows of the dataset look like\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check the types of the columns\n",
    "heart.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create lists of categorical, numerical and label columns\n",
    "catfeat = ['slope_of_peak_exercise_st_segment', 'thal', 'chest_pain_type', 'num_major_vessels', 'fasting_blood_sugar_gt_120_mg_per_dl', 'resting_ekg_results', 'sex']\n",
    "numfeat = [ 'resting_blood_pressure', 'serum_cholesterol_mg_per_dl', 'oldpeak_eq_st_depression', 'age', 'max_heart_rate_achieved']\n",
    "label = 'heart_disease_present'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#convert categorical columns to categories\n",
    "for col in catfeat:\n",
    "    heart[col] = heart[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check if it worked\n",
    "heart.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check the content of the colums again\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check for missing values\n",
    "print(\"Missings coded as NAs: \\n\", heart.isnull().any())\n",
    "\n",
    "print(\"\\n Missings coded as ?: \\n\", (heart.astype(np.object) == '?').any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplicate rows\n",
    "print(heart.shape)\n",
    "print(heart.index.unique().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#investigate descriptive statistics for numeric features\n",
    "heart[numfeat].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigate distribution propoerties kurtosis and skewness of numeric features\n",
    "\n",
    "for col in numfeat: \n",
    "    print(col, ': \\nexcess kurtosis (should be 0): {}'.format(stats.kurtosis(heart[col])))\n",
    "    print('skewness of (should be 0): {}'.format(stats.skew(heart[col])))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Visualize numeric feature distribution with displots \n",
    "def hist(df, cols, nbins):\n",
    "    for col in cols:\n",
    "        sns.distplot(df[col], bins = nbins )\n",
    "        plt.xlabel(col)\n",
    "        plt.show()\n",
    "\n",
    "hist(heart, numfeat, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test for normality\n",
    "\n",
    "for col in numfeat:\n",
    "    shst, p = stats.shapiro(heart[col])\n",
    "    print(col, ':')\n",
    "    print('Test statistic: ', shst)\n",
    "    print('P-Value for: ', p, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#visualize correlations between numerical features in a heat map\n",
    "corr = abs(heart[numfeat].corr())\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Vizualize label separation by numeric features with a box plot\n",
    "def plot_box(df, cols, col_x = label):\n",
    "    for col in cols:\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.boxplot(col_x, col, data=df)\n",
    "        plt.xlabel(col_x) # Set text for the x axis\n",
    "        plt.ylabel(col)# Set text for y axis\n",
    "        plt.show()\n",
    "\n",
    "plot_box(heart, numfeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#test the relationships between the numerical features and the label\n",
    "\n",
    "for col in numfeat:\n",
    "    print(col, \"and the label: \\n\", stats.pointbiserialr(heart[col], heart[label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#investigate descriptive statistics for categorical features\n",
    "heart[catfeat].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#visualize the number of cases per category with bar charts\n",
    "for col in catfeat: \n",
    "    nrcat = heart[col].value_counts()\n",
    "    nrcat.plot.bar(rot=1)\n",
    "    plt.ylabel(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Vizualize label separation by categorical features with a bar charts\n",
    "heart['dummy'] = np.ones(shape = heart.shape[0])\n",
    "\n",
    "for col in catfeat:\n",
    "    print(col)\n",
    "    counts = heart[['dummy', label, col]].groupby([label, col], as_index = False).count()\n",
    "    temp = counts[counts[label] == 0][[col, 'dummy']]\n",
    "    _ = plt.figure(figsize = (10,4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    temp = counts[counts[label] == 0][[col, 'dummy']]\n",
    "    plt.bar(temp[col], temp.dummy)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title('Counts for ' + col + ' and no heart disease')\n",
    "    plt.ylabel('count')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    temp = counts[counts[label] == 1][[col, 'dummy']]\n",
    "    plt.bar(temp[col], temp.dummy)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title('Counts for ' + col + ' and heart disease')\n",
    "    plt.ylabel('count')\n",
    "    plt.show()\n",
    "\n",
    "del heart['dummy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#test the relationships between the categorical features and the label\n",
    "\n",
    "for col in catfeat:\n",
    "    ct = pd.crosstab(heart[col], heart[label])\n",
    "    print(col, \": \\n\", stats.chisquare(ct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#visualize class distribution of the label\n",
    "heart_counts = heart[label].value_counts()\n",
    "heart_sum = sum(heart_counts)\n",
    "heart_perc = heart_counts / heart_sum\n",
    "\n",
    "heart_perc.plot.bar(rot=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "What did you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating categories\n",
    "\n",
    "Do we need to aggregate categories?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming numeric variables\n",
    "\n",
    "Which feature is not normally distributed and needs to be transformed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#transform 'oldpeak_eq_st_depression' with a square root and compare the distributions\n",
    "\n",
    "heart['sqr_depression'] = np.sqrt((heart['oldpeak_eq_st_depression']))\n",
    "\n",
    "hist(heart, ['sqr_depression', 'oldpeak_eq_st_depression'], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create a new categorical feature called 'rng_depression' from 'oldpeak_eq_st_depression'\n",
    "\n",
    "maxs = heart['oldpeak_eq_st_depression'].max()\n",
    "bin = [-1, 1 ,maxs]\n",
    "\n",
    "heart['rng_depression'] = pd.cut(heart['oldpeak_eq_st_depression'],bin)\n",
    "\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize counts of rng_depression categories with a bar chart\n",
    "\n",
    "rng_dep_counts = heart['rng_depression'].value_counts()\n",
    "\n",
    "rng_dep_counts.plot.bar(rot=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "What did you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define categorical and numerical features used for modelling\n",
    "sel_catfeat = ['rng_depression', 'slope_of_peak_exercise_st_segment', 'thal', 'chest_pain_type', 'num_major_vessels', 'sex']\n",
    "sel_numfeat = ['max_heart_rate_achieved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encode categorical features and concatenate them all into a new df\n",
    "\n",
    "heart_prep = pd.DataFrame(heart.index).set_index('patient_id')\n",
    "\n",
    "for col in sel_catfeat:\n",
    "    temp = pd.DataFrame(pd.get_dummies(heart[col], prefix=col))\n",
    "    heart_prep = pd.concat([heart_prep, temp], axis=1, join_axes=[heart_prep.index])\n",
    "\n",
    "heart_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add selected numerical features to new df\n",
    "heart_prep[sel_numfeat] = heart[sel_numfeat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize numerical features\n",
    "for col in sel_numfeat: \n",
    "    heart_prep[col] = preprocessing.scale(heart_prep[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the prepared dataset in a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a numpy array of train features\n",
    "np_train_feat = np.array(heart_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a numpy array of the label\n",
    "np_train_label = np.array(heart[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the new dataset into a training and test dataset and check their shapes\n",
    "x_train, x_test, y_train, y_test = ms.train_test_split(np_train_feat, np_train_label, test_size=0.33, random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and test a model using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the algorithm \n",
    "logistic_mod = linear_model.LogisticRegression() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do a randmized hyperparamter grid search\n",
    "penalty = ['l1', 'l2']\n",
    "C = stats.uniform(loc=0, scale=4)\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "lr_rs = ms.RandomizedSearchCV(logistic_mod, hyperparameters, random_state=1, n_iter=100, cv=5, verbose=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the randmized search and view the best hyperparameter \n",
    "lr_best_model = lr_rs.fit(x_train, y_train)   \n",
    "\n",
    "print('Best Penalty:', lr_best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', lr_best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create predictions with the model\n",
    "lr_probabilities = lr_best_model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to transform probabilities into class scores\n",
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "lr_scores = score_model(lr_probabilities, 0.5)\n",
    "print(np.array(lr_scores[:15]))\n",
    "print(y_test[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the predictions with a confusion matrix, accuracy, precision, recall and F1\n",
    "def print_metrics(labels, scores):\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy  %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "\n",
    "   \n",
    "print_metrics(y_test, lr_scores)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the log loss evaluation metric\n",
    "sklm.log_loss(y_test, lr_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and test a model using Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the algorithm \n",
    "SVM_mod = SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do a randmized hyperparamter grid search\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "C = stats.uniform(loc=0, scale=4)\n",
    "hyperparameters = dict(C=C, kernel=kernel)\n",
    "\n",
    "SVM_rs = ms.RandomizedSearchCV(SVM_mod, hyperparameters, random_state=1, n_iter=100, cv=5, verbose=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the randmized search and view the best hyperparameter \n",
    "SVM_best_model = SVM_rs.fit(x_train, y_train)   \n",
    "\n",
    "print('Best Kernel:', SVM_best_model.best_estimator_.get_params()['kernel'])\n",
    "print('Best C:', SVM_best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create predictions with the model\n",
    "SVM_probabilities = SVM_best_model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform probabilities into class scores\n",
    "SVM_scores = score_model(SVM_probabilities, 0.5)\n",
    "print(np.array(SVM_scores[:15]))\n",
    "print(y_test[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#evaluate the predictions with a confusion matrix, accuracy, precision, recall and F1\n",
    "print_metrics(y_test, SVM_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the log loss evaluation metric\n",
    "sklm.log_loss(y_test, SVM_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "What did you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling with AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define workspace parameters\n",
    "subscription_id = os.getenv('SUBSCRIPTION_ID', default='...')\n",
    "resource_group = os.getenv('RESOURCE_GROUP', default='...')\n",
    "workspace_name = os.getenv('WORKSPACE_NAME', default='...')\n",
    "workspace_region = os.getenv('WORKSPACE_REGION', default='...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if workspace already exists\n",
    "try:\n",
    "    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "    ws.write_config(path=os.path.abspath('..'), file_name='config.json')\n",
    "    print(\"Workspace configuration succeeded. Skip the workspace creation steps below\")\n",
    "except:\n",
    "    print(\"Workspace not accessible. Change your parameters or create a new workspace below\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a workspace and config file if it does not yet exist\n",
    "ws = Workspace.create(name=workspace_name,\n",
    "            subscription_id=subscription_id, \n",
    "            resource_group=resource_group,\n",
    "            create_resource_group = True,\n",
    "            location=workspace_region\n",
    "            )\n",
    "\n",
    "ws.write_config(path=os.path.abspath('..'), file_name='config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load workspace configuration from the config.json file in the root directory\n",
    "ws = Workspace.from_config(path=os.path.abspath('..'))\n",
    "print(ws.name, ws.resource_group, ws.location, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure AutoML\n",
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             iteration_timeout_minutes = 10,\n",
    "                             iterations = 10,\n",
    "                             primary_metric = 'precision_score_weighted',\n",
    "                             n_cross_validations = 5,\n",
    "                             debug_log = 'automl.log',\n",
    "                             verbosity = logging.INFO,\n",
    "                             X = x_train, \n",
    "                             y = y_train,\n",
    "                             preprocess=True,\n",
    "                             path = project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit the run\n",
    "local_run = experiment.submit(automl_config, show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show run details\n",
    "RunDetails(local_run).show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to do all the preprocessing with the test data\n",
    "def preprocess(df):\n",
    "    #define categorical and numerical features used for modelling\n",
    "    sel_catfeat = ['rng_depression', 'slope_of_peak_exercise_st_segment', 'thal', 'chest_pain_type', 'num_major_vessels', 'sex']\n",
    "    sel_numfeat = ['max_heart_rate_achieved']\n",
    "    \n",
    "    #create a new categorical feature called 'rng_depression' from 'oldpeak_eq_st_depression'\n",
    "    maxs = df['oldpeak_eq_st_depression'].max()\n",
    "    bin = [-1, 1 ,maxs]\n",
    "    df['rng_depression'] = pd.cut(df['oldpeak_eq_st_depression'],bin)\n",
    "    \n",
    "    #One hot encode categorical features and concatenate them all into a new df\n",
    "    df_prep = pd.DataFrame(df.index).set_index('patient_id')\n",
    "    for col in sel_catfeat:\n",
    "        temp = pd.DataFrame(pd.get_dummies(df[col], prefix=col))\n",
    "        df_prep = pd.concat([df_prep, temp], axis=1, join_axes=[df_prep.index])\n",
    "        \n",
    "    #add selected numerical features to new df\n",
    "    df_prep[sel_numfeat] = df[sel_numfeat]\n",
    "    \n",
    "    #standardize numerical features\n",
    "    for col in sel_numfeat: \n",
    "        df_prep[col] = preprocessing.scale(df_prep[col])\n",
    "    \n",
    "    #create a numpy array of train features\n",
    "    np_prep = np.array(df_prep)\n",
    "    \n",
    "    return np_prep\n",
    "    \n",
    "test_features_proc = preprocess(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check if the preprocessing worked\n",
    "print(test_features_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create predictions with the logistic regression model (Do not convert to binary labels, submissions must be made with probabilities)\n",
    "submission_probs = lr_best_model.predict_proba(test_features_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the predictions to the submission file and save it as csv\n",
    "submission_format['heart_disease_present'] = submission_probs\n",
    "\n",
    "submission_format.to_csv(os.path.join(data_folder, 'test-predictions.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
