{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an analysis for the DrivenData competition on predicting Heart Disease: https://www.drivendata.org/competitions/54/machine-learning-with-a-heart/page/107/\n",
    "\n",
    "The goal is to predict the binary class ```heart_disease_present```, which represents whether or not a patient has heart disease:\n",
    "\n",
    "- ```0``` represents no heart disease present\n",
    "- ```1``` represents heart disease present\n",
    "\n",
    "There are 14 columns in the dataset, where the ```patient_id``` column is a unique and random identifier. The remaining 13 features are described in the section below.\n",
    "- ```slope_of_peak_exercise_st_segment``` (type: int): the slope of the peak exercise ST segment, an electrocardiography read out indicating quality of blood flow to the heart\n",
    "- ```thal``` (type: categorical): results of thallium stress test measuring blood flow to the heart, with possible values ```normal```, ```fixed_defect```, ```reversible_defect```\n",
    "- ```resting_blood_pressure``` (type: int): resting blood pressure\n",
    "- ```chest_pain_type``` (type: int): chest pain type (4 values)\n",
    "- ```num_major_vessels``` (type: int): number of major vessels (0-3) colored by flourosopy\n",
    "- ```fasting_blood_sugar_gt_120_mg_per_dl``` (type: binary): fasting blood sugar > 120 mg/dl\n",
    "- ```resting_ekg_results``` (type: int): resting electrocardiographic results (values 0,1,2)\n",
    "- ```serum_cholesterol_mg_per_dl``` (type: int): serum cholestoral in mg/dl\n",
    "- ```oldpeak_eq_st_depression``` (type: float): oldpeak = ST depression induced by exercise relative to - rest, a measure of abnormality in electrocardiograms\n",
    "- ```sex``` (type: binary): ```0```: female, ```1```: male\n",
    "- ```age``` (type: int): age in years\n",
    "- ```max_heart_rate_achieved``` (type: int): maximum heart rate achieved (beats per minute)\n",
    "- ```exercise_induced_angina``` (type: binary): exercise-induced chest pain (```0```: False, ```1```: True)\n",
    "\n",
    "Performance is evaluated according to binary log loss.\n",
    "\n",
    "The format for the submission file is two columns with the ```patient_id``` and ```heart_disease_present```. This competition uses log loss as its evaluation metric, so the ```heart_disease_present``` values you should submit are the probabilities that a patient has heart disease (not the binary label)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load required packages\n",
    "\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as sklm\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import define and create the data folder\n",
    "data_folder = os.path.join(os.getcwd(), 'Data')\n",
    "os.makedirs(data_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#download the data\n",
    "urllib.request.urlretrieve('https://s3.amazonaws.com/drivendata/data/54/public/train_values.csv', filename=os.path.join(data_folder, 'train-features.csv'))\n",
    "urllib.request.urlretrieve('https://s3.amazonaws.com/drivendata/data/54/public/train_labels.csv', filename=os.path.join(data_folder, 'train-labels.csv'))\n",
    "urllib.request.urlretrieve('https://s3.amazonaws.com/drivendata/data/54/public/test_values.csv', filename=os.path.join(data_folder, 'test-features.csv'))\n",
    "urllib.request.urlretrieve('https://s3.amazonaws.com/drivendata/data/54/public/submission_format.csv', filename=os.path.join(data_folder, 'submission-format.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import the data into the notebook and defined first column as index (patient id)\n",
    "train_features = pd.read_csv(os.path.join(data_folder, 'train-features.csv'),index_col=0)\n",
    "train_labels = pd.read_csv(os.path.join(data_folder, 'train-labels.csv'), index_col=0)\n",
    "test_features = pd.read_csv(os.path.join(data_folder, 'test-features.csv'), index_col=0)\n",
    "submission_format = pd.read_csv(os.path.join(data_folder, 'submission-format.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create one training dataframe\n",
    "\n",
    "train_features['heart_disease_present'] = train_labels['heart_disease_present']\n",
    "\n",
    "heart = train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#check how the first rows of the dataset look like\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check the types of the columns\n",
    "heart.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create lists of categorical, numerical and label columns\n",
    "catfeat = ['slope_of_peak_exercise_st_segment', 'thal', 'chest_pain_type', 'num_major_vessels', 'fasting_blood_sugar_gt_120_mg_per_dl', 'resting_ekg_results', 'sex']\n",
    "numfeat = [ 'resting_blood_pressure', 'serum_cholesterol_mg_per_dl', 'oldpeak_eq_st_depression', 'age', 'max_heart_rate_achieved']\n",
    "label = 'heart_disease_present'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#convert categorical columns to categories\n",
    "for col in catfeat:\n",
    "    heart[col] = heart[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check if it worked\n",
    "heart.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check the content of the colums again\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check for missing values\n",
    "print(\"Missings coded as NAs: \\n\", heart.isnull().any())\n",
    "\n",
    "print(\"\\n Missings coded as ?: \\n\", (heart.astype(np.object) == '?').any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplicate rows\n",
    "print(heart.shape)\n",
    "print(heart.index.unique().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#investigate descriptive statistics for numeric features\n",
    "heart[numfeat].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigate distribution propoerties kurtosis and skewness of numeric features\n",
    "\n",
    "for col in numfeat: \n",
    "    print(col, ': \\nexcess kurtosis (should be 0): {}'.format(stats.kurtosis(heart[col])))\n",
    "    print('skewness of (should be 0): {}'.format(stats.skew(heart[col])))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Visualize numeric feature distribution with displots \n",
    "def hist(df, cols, nbins):\n",
    "    for col in cols:\n",
    "        sns.distplot(df[col], bins = nbins )\n",
    "        plt.xlabel(col)\n",
    "        plt.show()\n",
    "\n",
    "hist(heart, numfeat, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test for normality\n",
    "\n",
    "for col in numfeat:\n",
    "    shst, p = stats.shapiro(heart[col])\n",
    "    print(col, ':')\n",
    "    print('Test statistic: ', shst)\n",
    "    print('P-Value for: ', p, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#visualize correlations between numerical features in a heat map\n",
    "corr = abs(heart[numfeat].corr())\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Vizualize label separation by numeric features with a box plot\n",
    "def plot_box(df, cols, col_x = label):\n",
    "    for col in cols:\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        sns.boxplot(col_x, col, data=df)\n",
    "        plt.xlabel(col_x) # Set text for the x axis\n",
    "        plt.ylabel(col)# Set text for y axis\n",
    "        plt.show()\n",
    "\n",
    "plot_box(heart, numfeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#test the relationships between the numerical features and the label\n",
    "\n",
    "for col in numfeat:\n",
    "    print(col, \"and the label: \\n\", stats.pointbiserialr(heart[col], heart[label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#investigate descriptive statistics for categorical features\n",
    "heart[catfeat].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#visualize the number of cases per category with bar charts\n",
    "for col in catfeat: \n",
    "    nrcat = heart[col].value_counts()\n",
    "    nrcat.plot.bar(rot=1)\n",
    "    plt.ylabel(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Vizualize label separation by categorical features with a bar charts\n",
    "heart['dummy'] = np.ones(shape = heart.shape[0])\n",
    "\n",
    "for col in catfeat:\n",
    "    print(col)\n",
    "    counts = heart[['dummy', label, col]].groupby([label, col], as_index = False).count()\n",
    "    temp = counts[counts[label] == 0][[col, 'dummy']]\n",
    "    _ = plt.figure(figsize = (10,4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    temp = counts[counts[label] == 0][[col, 'dummy']]\n",
    "    plt.bar(temp[col], temp.dummy)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title('Counts for ' + col + ' and no heart disease')\n",
    "    plt.ylabel('count')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    temp = counts[counts[label] == 1][[col, 'dummy']]\n",
    "    plt.bar(temp[col], temp.dummy)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title('Counts for ' + col + ' and heart disease')\n",
    "    plt.ylabel('count')\n",
    "    plt.show()\n",
    "\n",
    "del heart['dummy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#test the relationships between the categorical features and the label\n",
    "\n",
    "for col in catfeat:\n",
    "    ct = pd.crosstab(heart[col], heart[label])\n",
    "    print(col, \": \\n\", stats.chisquare(ct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#visualize class distribution of the label\n",
    "heart_counts = heart[label].value_counts()\n",
    "heart_sum = sum(heart_counts)\n",
    "heart_perc = heart_counts / heart_sum\n",
    "\n",
    "heart_perc.plot.bar(rot=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- No missing values\n",
    "\n",
    "\n",
    "- ```age``` is the only feature that is statisticall normally distributed\n",
    "- The distribution of ```serum_cholesterol_mg_per_dl``` and  ```oldpeak_eq_st_depression``` differ the most from normal distributions\n",
    "- ```serum_cholesterol_mg_per_dl``` contains extreme outliers, but apart from the outliers the form resembles a normal distribution\n",
    "- ```oldpeak_eq_st_depression``` also contains outliers, but the form does not resemble a normal distribution even when ignoring the outliers\n",
    "- numerical features have low to medium intercorrelations\n",
    "- ```oldpeak_eq_st_depression``` and ```max_heart_rate_achieved```  can visually distinguish the best between heart and no heart disease, this is confirmed when calculating a point biserial correlation.\n",
    "- Interestingly, ```serum_cholesterol_mg_per_dl``` does not distinguish so well between heart and no heart disease. \n",
    "\n",
    "\n",
    "- most of the categorical features have categories with very little data\n",
    "- categories that distinguish well between heart and no heart disease are ```slope_of_peak_exercise_st_segment```, ```thal```, ```chest_pain_type```, ```num_major_vessels``` and ```sex```\n",
    "\n",
    "\n",
    "- the number of cases in the label variables are more or less equal and thus no undersampling is required\n",
    "\n",
    "\n",
    "- Thus, the features and are further investigated and taken for predictions in the first run are ```oldpeak_eq_st_depression```, ```max_heart_rate_achieved```, ```slope_of_peak_exercise_st_segment```, ```thal```, ```chest_pain_type```, ```num_major_vessels``` and ```sex```. \n",
    "- For ```resting_blood_pressure```, ```fasting_blood_sugar_gt_120_mg_per_dl```, ```resting_ekg_results```, ```serum_cholesterol_mg_per_dl```, ```age``` and ```exercise_induced_angina```, further feature engineering will be performed in a second run through."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating categories\n",
    "\n",
    "Of the requencies that distinguish well between heart and no heart disease, ```slope_of_peak_exercise_st_segment```, ```thal```, ```chest_pain_type```, ```num_major_vessels``` contain categories with a small amount of cases.\n",
    "\n",
    "However, one must be careful with aggregating categories. This only makes sense for categories that are similar in the domain of the problem. Thus, domain expertise must be applied. \n",
    "\n",
    "We will leave them for now as they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming numeric variables\n",
    "\n",
    "```oldpeak_eq_st_depression``` is not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#transform 'oldpeak_eq_st_depression' with a square root and compare the distributions\n",
    "\n",
    "heart['sqr_depression'] = np.sqrt((heart['oldpeak_eq_st_depression']))\n",
    "\n",
    "hist(heart, ['sqr_depression', 'oldpeak_eq_st_depression'], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create a new categorical feature called 'rng_depression' from 'oldpeak_eq_st_depression'\n",
    "\n",
    "maxs = heart['oldpeak_eq_st_depression'].max()\n",
    "bin = [-1, 1 ,maxs]\n",
    "\n",
    "heart['rng_depression'] = pd.cut(heart['oldpeak_eq_st_depression'],bin)\n",
    "\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize counts of rng_depression categories with a bar chart\n",
    "\n",
    "rng_dep_counts = heart['rng_depression'].value_counts()\n",
    "\n",
    "rng_dep_counts.plot.bar(rot=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- log-transforming ```oldpeak_eq_st_depression``` is not suitable as it contains predominantly 0 values\n",
    "- transforming ```oldpeak_eq_st_depression``` by applying the square root resulted in a distribution that seemed to contain two subdistributions\n",
    "- ```oldpeak_eq_st_depression``` is thus converted into the categorical feature ```rng_depression``` with two categories: cases with a 0-level of depression and cases with a level higher than 0 of depression\n",
    "\n",
    "\n",
    "- Features taken for building a model are ```rng_depression```, ```max_heart_rate_achieved```, ```slope_of_peak_exercise_st_segment```, ```thal```, ```chest_pain_type```, ```num_major_vessels``` and ```sex```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define categorical and numerical features used for modelling\n",
    "sel_catfeat = ['rng_depression', 'slope_of_peak_exercise_st_segment', 'thal', 'chest_pain_type', 'num_major_vessels', 'sex']\n",
    "sel_numfeat = ['max_heart_rate_achieved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encode categorical features and concatenate them all into a new df\n",
    "\n",
    "heart_prep = pd.DataFrame(heart.index).set_index('patient_id')\n",
    "\n",
    "for col in sel_catfeat:\n",
    "    temp = pd.DataFrame(pd.get_dummies(heart[col], prefix=col))\n",
    "    heart_prep = pd.concat([heart_prep, temp], axis=1, join_axes=[heart_prep.index])\n",
    "\n",
    "heart_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add selected numerical features to new df\n",
    "heart_prep[sel_numfeat] = heart[sel_numfeat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize numerical features\n",
    "for col in sel_numfeat: \n",
    "    heart_prep[col] = preprocessing.scale(heart_prep[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the prepared dataset in a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a numpy array of train features\n",
    "np_train_feat = np.array(heart_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a numpy array of the label\n",
    "np_train_label = np.array(heart[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the new dataset into a training and test dataset and check their shapes\n",
    "x_train, x_test, y_train, y_test = ms.train_test_split(np_train_feat, np_train_label, test_size=0.33, random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and test a model using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "logistic_mod = linear_model.LogisticRegression() \n",
    "logistic_mod.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create predictions with the model\n",
    "probabilities = logistic_mod.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform probabilities into class scores\n",
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "scores = score_model(probabilities, 0.5)\n",
    "print(np.array(scores[:15]))\n",
    "print(y_test[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the predictions with a confusion matrix, accuracy, precision, recall and F1\n",
    "def print_metrics(labels, scores):\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy  %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "\n",
    "   \n",
    "print_metrics(y_test, scores)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the log loss evaluation metric\n",
    "sklm.log_loss(y_test, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the predictions with the ROC curve and AUC\n",
    "def plot_auc(labels, probs):\n",
    "    ## Compute the false positive rate, true positive rate\n",
    "    ## and threshold along with the AUC\n",
    "    fpr, tpr, threshold = sklm.roc_curve(labels, probs[:,1])\n",
    "    auc = sklm.auc(fpr, tpr)\n",
    "    \n",
    "    ## Plot the result\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, color = 'orange', label = 'AUC = %0.2f' % auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    \n",
    "plot_auc(y_test, probabilities)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling in AMLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling with AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to do all the preprocessing with the test data\n",
    "def preprocess(df):\n",
    "    #define categorical and numerical features used for modelling\n",
    "    sel_catfeat = ['rng_depression', 'slope_of_peak_exercise_st_segment', 'thal', 'chest_pain_type', 'num_major_vessels', 'sex']\n",
    "    sel_numfeat = ['max_heart_rate_achieved']\n",
    "    \n",
    "    #create a new categorical feature called 'rng_depression' from 'oldpeak_eq_st_depression'\n",
    "    maxs = df['oldpeak_eq_st_depression'].max()\n",
    "    bin = [-1, 1 ,maxs]\n",
    "    df['rng_depression'] = pd.cut(df['oldpeak_eq_st_depression'],bin)\n",
    "    \n",
    "    #One hot encode categorical features and concatenate them all into a new df\n",
    "    df_prep = pd.DataFrame(df.index).set_index('patient_id')\n",
    "    for col in sel_catfeat:\n",
    "        temp = pd.DataFrame(pd.get_dummies(df[col], prefix=col))\n",
    "        df_prep = pd.concat([df_prep, temp], axis=1, join_axes=[df_prep.index])\n",
    "        \n",
    "    #add selected numerical features to new df\n",
    "    df_prep[sel_numfeat] = df[sel_numfeat]\n",
    "    \n",
    "    #standardize numerical features\n",
    "    for col in sel_numfeat: \n",
    "        df_prep[col] = preprocessing.scale(df_prep[col])\n",
    "    \n",
    "    #create a numpy array of train features\n",
    "    np_prep = np.array(df_prep)\n",
    "    \n",
    "    return np_prep\n",
    "    \n",
    "test_features_proc = preprocess(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check if the preprocessing worked\n",
    "print(test_features_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create predictions with the model (Do not convert to binary labels, submissions must be made with probabilities)\n",
    "submission_probs = logistic_mod.predict_proba(test_features_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the predictions to the submission file and save it as csv\n",
    "submission_format['heart_disease_present'] = submission_probs\n",
    "\n",
    "submission_format.to_csv(os.path.join(data_folder, 'test-predictions.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
